{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Project: A Simple Search Engine from Scratch\n",
    "In this mini-project you will study the fundaments of IR.\n",
    "\n",
    "The mini-project is divided as follow:\n",
    "\n",
    "- **Week 1**: Study the provided notebook. Using the VSM retrieval model, run experiments *(section 4)* with the provided collection. Compute the metrics MAP, P10 and precision-recall curves.\n",
    "\n",
    "- **Week 2**: Implement the LMD and LMJM retrieval models and repeat the experiments with the new models. Compare it to the previous retrieval models.\n",
    "\n",
    "- **Week 3**: Implement the RM3 retrieval model and repeat the experiments with the new models. Compare it to the previous retrieval models.\n",
    "\n",
    "- **Week 4**: Implement the BM25 retrieval model and repeat the experiments with the new models. Compare it to the previous retrieval models.\n",
    "\n",
    "**Submission date: 15 October**\n",
    "\n",
    "## 1. Vector Space Model\n",
    "\n",
    "In the vector space model, documents are represented as a vector $d_j=(w_{d_j,1},w_{d_j,2}, ..., w_{d_j,n})$ of $n$ word frequencies -- most of the words are equal to 0. Queries are also represented as a vector of words $q_j=(w_{q_j,1},w_{q_j,2}, ..., w_{q_j,n})$. In the vector space model, each document word is weighted by their *tf-idf*\n",
    "\n",
    "$${tf-idf} = tf*\\frac{|D|}{log (df(w_a))}$$\n",
    "\n",
    "The vector space model is based on the cosine similarity, which measures the angle between the two vectors in the 1-unit sphere:\n",
    "\n",
    "$$cos(q,d) = \\frac{\\sum_t q_t\\cdot d_t}{\\sqrt{\\sum_t q^2_t}\\cdot \\sqrt{\\sum_t d^2_t }}$$\n",
    "\n",
    "\n",
    "Below you can read the corresponding matricial implementation for multiple documents.\n",
    "\n",
    "### Parser\n",
    "Using the CountVectorizer class of Scikit-Learn, try the different parser options by generating unigrams and bigrams with different stop words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer #faz a separação de um texto em palavras\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2), #max number of words a vector entry can have\n",
    "                                    token_pattern=r'\\b\\w+\\b', #regExp that select one word or infinite words (w+)\n",
    "                                    min_df=1, #min frequency, if it is int only if the word appears int times it will be stored\n",
    "                                    stop_words = {'the', 'is'} #words that are irrelevant to the search\n",
    "                                   )\n",
    "\n",
    "corpus = ['This is the first document.',\n",
    "'This is the second second document.',\n",
    "'And the third one.',\n",
    "'Is this the first document?', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'text', 'document', 'to', 'analyze', 'the', 'analyser']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_analyze = vectorizer.build_analyzer()\n",
    "uni_analyze(\"This is a text document to analyze the analyser.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 1 0 1 0 2 1 0 1]\n",
      " [1 0 0 0 1 0 1 1 0]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "tf_uni = vectorizer.fit_transform(corpus).toarray()\n",
    "print(vectorizer.get_feature_names())\n",
    "print()\n",
    "print(tf_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'a',\n",
       " 'text',\n",
       " 'document',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'this a',\n",
       " 'a text',\n",
       " 'text document',\n",
       " 'document to',\n",
       " 'to analyze']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_analyze = bigram_vectorizer.build_analyzer()\n",
    "bi_analyze(\"This is a text document to analyze.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'and third', 'document', 'first', 'first document', 'one', 'second', 'second document', 'second second', 'third', 'third one', 'this', 'this first', 'this second']\n",
      "\n",
      "[[0 0 1 1 1 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 1 0 0 0 2 1 1 0 0 1 0 1]\n",
      " [1 1 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      " [0 0 1 1 1 0 0 0 0 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "tf_bi = bigram_vectorizer.fit_transform(corpus).toarray()\n",
    "print(bigram_vectorizer.get_feature_names())\n",
    "print()\n",
    "print(tf_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(bigram_vectorizer.vocabulary_.get('document')) # returns the index of the word in the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF IDF and the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tf:\n",
      " [[0 1 1 1 0 0 1 0 1]\n",
      " [0 1 0 1 0 2 1 0 1]\n",
      " [1 0 0 0 1 0 1 1 0]\n",
      " [0 1 1 1 0 0 1 0 1]]\n",
      "\n",
      "idf:\n",
      " [1.38629436 0.28768207 0.69314718 0.28768207 1.38629436 1.38629436\n",
      " 0.         1.38629436 0.28768207]\n",
      "\n",
      "tfidf:\n",
      " [[0.         0.28768207 0.69314718 0.28768207 0.         0.\n",
      "  0.         0.         0.28768207]\n",
      " [0.         0.28768207 0.         0.28768207 0.         2.77258872\n",
      "  0.         0.         0.28768207]\n",
      " [1.38629436 0.         0.         0.         1.38629436 0.\n",
      "  0.         1.38629436 0.        ]\n",
      " [0.         0.28768207 0.69314718 0.28768207 0.         0.\n",
      "  0.         0.         0.28768207]]\n",
      "\n",
      "docnorms:\n",
      " [0.85366032 2.81700748 2.40113227 0.85366032]\n"
     ]
    }
   ],
   "source": [
    "termCollFreq = np.sum(tf_uni != 0, axis = 0) #axis = 0 -> eixo dos x\n",
    "docLen = np.sum(tf_uni, axis = 1) #axis = 1 -> eixo dos y\n",
    "\n",
    "idf = np.log(np.size(corpus)/termCollFreq)\n",
    "idf_rows = np.dot(np.ones((np.size(corpus),1)), #creates an identity matrix given the shape and type\n",
    "                  idf.reshape(1,np.size(idf)) #normalize the array\n",
    "                 )\n",
    "tfidf = tf_uni*idf_rows\n",
    "\n",
    "docNorms = np.sqrt(np.sum(np.power(tfidf,2), axis = 1)) #primeiro sqrt\n",
    "        \n",
    "print(\"\\ntf:\\n\", tf_uni)\n",
    "print(\"\\nidf:\\n\", idf)\n",
    "print(\"\\ntfidf:\\n\", tfidf)\n",
    "print(\"\\ndocnorms:\\n\", docNorms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((np.size(corpus),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3369983  0.10212329 0.         0.3369983 ]]\n"
     ]
    }
   ],
   "source": [
    "query = 'document'\n",
    "query_vector = vectorizer.transform([query]).toarray()\n",
    "queryNorm = np.sqrt(np.sum(np.power(query_vector, 2), axis = 1)) #segundo sqrt\n",
    "\n",
    "doc_scores = np.dot(query_vector, tfidf.T)/(docNorms*queryNorm) #formula acima\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted Index\n",
    "The matricial implementation is not scalable because it computes the similarity for all documents in the collection. However, one should only compute the similarity for the documents containing the query words. This is where the inverted index comes to our rescue.\n",
    "\n",
    "Read the inverted index implementation presented next. Describe in your own words how the cosine similarity should be implemented with the inverted index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Creating the posting list for token \" and \"\n",
      "[(1, 2)]\n",
      "==== Creating the posting list for token \" document \"\n",
      "[(1, 0), (1, 1), (1, 3)]\n",
      "==== Creating the posting list for token \" first \"\n",
      "[(1, 0), (1, 3)]\n",
      "==== Creating the posting list for token \" is \"\n",
      "[(1, 0), (1, 1), (1, 3)]\n",
      "==== Creating the posting list for token \" one \"\n",
      "[(1, 2)]\n",
      "==== Creating the posting list for token \" second \"\n",
      "[(2, 1)]\n",
      "==== Creating the posting list for token \" the \"\n",
      "[(1, 0), (1, 1), (1, 2), (1, 3)]\n",
      "==== Creating the posting list for token \" third \"\n",
      "[(1, 2)]\n",
      "==== Creating the posting list for token \" this \"\n",
      "[(1, 0), (1, 1), (1, 3)]\n"
     ]
    }
   ],
   "source": [
    "features = vectorizer.get_feature_names()\n",
    "\n",
    "i = 0\n",
    "inverted_index = dict()\n",
    "for token in features:\n",
    "    print(\"==== Creating the posting list for token \\\"\", token, \"\\\"\")\n",
    "    docs_with_token = np.where(tf_uni[:,i] != 0)\n",
    "    len = np.size(docs_with_token,1)\n",
    "    \n",
    "    postings_matrix = np.concatenate([tf_uni[docs_with_token,i], docs_with_token])\n",
    "    postings_list = list(map(tuple, postings_matrix.T))\n",
    "    inverted_index[token] = postings_list\n",
    "\n",
    "    print(postings_list)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Using the Vector Space Model, run the experiments of section 4.\n",
    "\n",
    "We advice you to use an external Python IDE for editing more complex implementations. **The Notebook should be used as a notebook, not as an IDE**. Your implementations should be organized on external classes as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3369983 , 0.19528704, 0.        , 0.3369983 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import RetrievalModelsMatrix as b\n",
    "\n",
    "aa = b.RetrievalModelsMatrix(tf_uni, vectorizer)\n",
    "\n",
    "aa.score_vsm('document')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieval Models\n",
    "\n",
    "In this section you will implement three of the most popular retrieval model. After finishing each retrieval model implementation, run the experiments of section 4 with the new model.\n",
    "\n",
    "### Language Model with Jelineck-Mercer Smoothing (20%)\n",
    "The family of Language Models for retrieval build on the density distribution of the terms over each document and the density distribution of terms over the collection of documents.\n",
    "\n",
    "There several ways of avoiding the zero probabilities problem with term smoothing.  The Jelineck-Mercer smoothing model uses a mixture of probabilities between the document model $M_d$ and the corpus model $M_c$:\n",
    "\n",
    "$$p(q|d,C)= \\lambda \\cdot p(q|M_d) + (1-\\lambda)\\cdot p(q|M_c)$$\n",
    "\n",
    "Implement the LMJM retrieval model using the matricial definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3369983  0.10212329 0.         0.3369983 ]]\n"
     ]
    }
   ],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: LMJM model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the LMJM retrieval model using the inverted-index data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3369983  0.10212329 0.         0.3369983 ]]\n"
     ]
    }
   ],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: LMJM model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model with Dirichlet Smoothing (20%)\n",
    "Another way of avoiding the zero probabilities problem is with the Dirichlet smoothing model that uses a mixture of frequencies between the term document frequencies $f_{t,c}$ and the term corpus frequency $\\mu \\cdot M_c(t)$:\n",
    "\n",
    "$$p(t|M_d, M_c)= \\frac{f_{t,d}+\\mu \\cdot M_c(t)}{|d| + \\mu}$$\n",
    "\n",
    "Implement the LMD retrieval model using the matricial definitions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3369983  0.10212329 0.         0.3369983 ]]\n"
     ]
    }
   ],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: LMD model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the LMD retrieval model using the inverted-index data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3369983  0.10212329 0.         0.3369983 ]]\n"
     ]
    }
   ],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: LMD model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM 25 (20%)\n",
    "\n",
    "The BM25 is model is an evolution of the tf-idf weighting based on a two Poisson distribution per term. It is obviously impossible to estimate each term distribution -- the approximation to the two Poisson distribution is given by the expression:\n",
    "\n",
    "$$RSV = \\sum q_t \\cdot \\frac{f_{t,d}(k_1 + 1)}{k_1 ((1-b) + b(\\frac{l_d}{l_avg})) + f_{t,d} }\\cdot IDF_t$$\n",
    "\n",
    "Implement the BM5 retrieval model using the matricial definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3369983  0.10212329 0.         0.3369983 ]]\n"
     ]
    }
   ],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: BM25 model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the BM25 retrieval model using the inverted-index data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3369983  0.10212329 0.         0.3369983 ]]\n"
     ]
    }
   ],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: BM25 model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Using the implemented Retrieval Models, run the experiments of section 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pseudo-Relevance Feedback (RM3) (20%)\n",
    "\n",
    "Using the RM3 Model, run the experiments of section 4.\n",
    "\n",
    "Implement the RM3 retrieval model using the matricial definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3369983  0.10212329 0.         0.3369983 ]]\n"
     ]
    }
   ],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: RM3 model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the RM3 retrieval model using the inverted-index data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3369983  0.10212329 0.         0.3369983 ]]\n"
     ]
    }
   ],
   "source": [
    "query = \"document\"\n",
    "\n",
    "# TO DO: RM3 model\n",
    "\n",
    "print(doc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Using the implemented RM3 model, run the experiments of section 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiments and Results (20%)\n",
    "The goal of this section is to compare experimentally the different retrieval models. In this section you must:\n",
    "- Load the Cranfield documents.\n",
    "- Run the implemented retrieval models\n",
    "- Plot the precision-recall curves.\n",
    "- Compute MAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
